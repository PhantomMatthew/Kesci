{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kesci competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7e4bea36baf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_raw = pd.read_csv('train_set.csv')\n",
    "\n",
    "#data\n",
    "test_raw = pd.read_csv('test_set.csv')\n",
    "\n",
    "#test_data\n",
    "print(train_raw.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据的指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for col in train_data.columns[train_data.dtypes == 'object']:\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(train_data[col])\n",
    "\n",
    "    train_data[col] = label_encoder.transform(train_data[col])\n",
    "    test_data[col] = label_encoder.transform(test_data[col])\n",
    "\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "scaler.fit(train_raw[['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']])\n",
    "\n",
    "train_raw[['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']]=scaler.transform(train_raw[['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']])\n",
    "test_raw[['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']]=scaler.transform(test_raw[['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']])\n",
    "\n",
    "train_raw.head(100)\n",
    "test_raw.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分割训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "prediction = train_data['y']\n",
    "\n",
    "train_use_col = list(set(train_data.columns) - set(['ID', 'y']))\n",
    "\n",
    "features = train_data[train_use_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prediction, test_size=0.2, random_state=55)\n",
    "\n",
    "print(features)\n",
    "\n",
    "print(\"Training and testing split was successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用lgb进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, label=y_test, reference=lgb_train)\n",
    "\n",
    "# params = {\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective': 'binary',\n",
    "#     'metric': {'auc'},\n",
    "#     'num_leaves': 5,\n",
    "#     'max_depth': 6,\n",
    "#     'min_data_in_leaf': 450,\n",
    "#     'learning_rate': 0.1,\n",
    "#     'feature_fraction': 0.9,\n",
    "#     'bagging_fraction': 0.95,\n",
    "#     'bagging_freq': 5,\n",
    "#     'lambda_l1': 1,\n",
    "#     'lambda_l2': 0.001,\n",
    "#     'min_gain_to_split': 0.2,\n",
    "#     'verbose': 5,\n",
    "#     'is_unbalance': True\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'auc'},\n",
    "    # 'max_bin': 255,\n",
    "    # 'num_leaves': 30,\n",
    "    # 'max_depth': 5,\n",
    "    # 'min_data_in_leaf': 450,\n",
    "    'learning_rate': 0.02,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.90,\n",
    "    'bagging_freq': 15,\n",
    "    'lambda_l1': 2,\n",
    "    'lambda_l2': 0.001,\n",
    "    # 'min_gain_to_split': 0.2,\n",
    "    # 'num_iterations': 100,\n",
    "    'verbose': 0,\n",
    "    'is_unbalance': True,\n",
    "    # 'num_leaves' : 50,\n",
    "    # 'num_trees' : 1000,\n",
    "    # 'num_threads' : 32,\n",
    "    # 'min_data_in_leaf' : 0,\n",
    "    # 'min_sum_hessian_in_leaf' : 15\n",
    "}\n",
    "\n",
    "# gbm = lgb.train(params,\n",
    "#                 lgb_train,\n",
    "#                 num_boost_round=1000,\n",
    "#                 valid_sets=lgb_eval,\n",
    "#                 valid_names=None,\n",
    "#                 fobj=None, feval=None, init_model=None,\n",
    "#                 feature_name='auto', categorical_feature=['job', 'marital','education','default','housing','loan','contact','poutcome'],\n",
    "#                 early_stopping_rounds=10, evals_result=None,\n",
    "#                 verbose_eval=True,\n",
    "#                 keep_training_booster=False, callbacks=None)\n",
    "\n",
    "model = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10000,\n",
    "                valid_sets=lgb_eval,\n",
    "                feature_name='auto',\n",
    "                # categorical_feature=['month','campaign','job', 'marital','education','default','contact','housing','contact','poutcome'],\n",
    "                # categorical_feature=['campaign', 'job', 'marital', 'education', 'default', 'contact','housing', 'contact', 'poutcome'],\n",
    "                # categorical_feature=['month','campaign','job', 'marital','education','contact','contact','poutcome'],\n",
    "                # categorical_feature=['month','campaign','job', 'balance', 'marital','education','contact','contact','poutcome'],\n",
    "                categorical_feature = 'auto',\n",
    "                # categorical_feature=['duration','day','balance', 'balance', 'month','age','pdays','job','campaign', 'education'],\n",
    "                early_stopping_rounds=1000\n",
    "                )\n",
    "\n",
    "preds = model.predict(test_data[train_use_col], num_iteration=model.best_iteration)\n",
    "\n",
    "test_data['pred'] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[['ID', 'pred']].to_csv(\"result.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "lgb.plot_importance(model, max_num_features=30)\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
